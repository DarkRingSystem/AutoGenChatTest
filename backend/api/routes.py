"""
API è·¯ç”±æ¨¡å—
å®šä¹‰æ‰€æœ‰ API ç«¯ç‚¹
"""
from fastapi import APIRouter, HTTPException, UploadFile, File, Form
from fastapi.responses import StreamingResponse
from typing import Optional, Dict
import uuid
import re

from models import (
    ChatRequest, ChatResponse, HealthResponse,
    MarkdownConvertRequest, MarkdownConvertResponse,
    BatchMarkdownConvertResponse,
    ImageAnalysisRequest, ImageAnalysisResponse
)
from core.dependencies import get_ai_service, get_stream_service, get_session_service
from config import settings

# æ–‡ä»¶å†…å®¹å­˜å‚¨ï¼ˆç®€å•çš„å†…å­˜å­˜å‚¨ï¼Œç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ•°æ®åº“æˆ–ç¼“å­˜ï¼‰
file_storage = {}

# å›¢é˜ŸæœåŠ¡ç¼“å­˜ï¼ˆç”¨äºä¿æŒå›¢é˜ŸçŠ¶æ€ï¼‰
_team_service_cache: Dict[str, any] = {}

router = APIRouter()


def _cache_team_service(conversation_id: str, team_service: any) -> None:
    """ç¼“å­˜å›¢é˜ŸæœåŠ¡å®ä¾‹"""
    _team_service_cache[conversation_id] = team_service
    print(f"ğŸ’¾ ç¼“å­˜å›¢é˜Ÿå®ä¾‹: {conversation_id}")


def _get_cached_team_service(conversation_id: str) -> Optional[any]:
    """è·å–ç¼“å­˜çš„å›¢é˜ŸæœåŠ¡å®ä¾‹"""
    return _team_service_cache.get(conversation_id)


def _remove_cached_team_service(conversation_id: str) -> None:
    """ç§»é™¤ç¼“å­˜çš„å›¢é˜ŸæœåŠ¡å®ä¾‹"""
    if conversation_id in _team_service_cache:
        del _team_service_cache[conversation_id]
        print(f"ğŸ—‘ï¸ ç§»é™¤å›¢é˜Ÿå®ä¾‹ç¼“å­˜: {conversation_id}")


def _parse_target_agent(message: str) -> Optional[str]:
    """
    è§£ææ¶ˆæ¯ä¸­çš„ç›®æ ‡æ™ºèƒ½ä½“

    æ”¯æŒæ ¼å¼ï¼š
    - @TestCase_Generator, @TestCase_Reviewer, @TestCase_Optimizer
    - @all (é‡æ–°è¿è¡Œ Generator â†’ Reviewer æµç¨‹)

    å‚æ•°:
        message: ç”¨æˆ·æ¶ˆæ¯

    è¿”å›:
        æ™ºèƒ½ä½“åç§°ã€"all" æˆ– None
    """
    # å…ˆåŒ¹é… @allï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    if re.search(r'@all\b', message, re.IGNORECASE):
        print(f"ğŸ”„ æ£€æµ‹åˆ° @allï¼Œå°†é‡æ–°è¿è¡Œ Generator â†’ Reviewer æµç¨‹")
        return "all"

    # åŒ¹é… @æ™ºèƒ½ä½“åç§°
    match = re.search(r'@(TestCase_\w+)', message)
    if match:
        agent_name = match.group(1)
        print(f"ğŸ¯ æ£€æµ‹åˆ°ç›®æ ‡æ™ºèƒ½ä½“: {agent_name}")
        return agent_name

    return None



def _build_message_with_file_context(message: str, file_ids: Optional[list[str]]) -> str:
    """
    æ„å»ºåŒ…å«æ–‡ä»¶ä¸Šä¸‹æ–‡çš„æ¶ˆæ¯

    å‚æ•°:
        message: ç”¨æˆ·åŸå§‹æ¶ˆæ¯
        file_ids: æ–‡ä»¶ ID åˆ—è¡¨

    è¿”å›:
        åŒ…å«æ–‡ä»¶ä¸Šä¸‹æ–‡çš„å®Œæ•´æ¶ˆæ¯
    """
    if not file_ids or len(file_ids) == 0:
        return message

    # è·å–æ–‡ä»¶å­˜å‚¨
    file_storage = get_file_storage()

    # è·å–æ–‡ä»¶å†…å®¹
    file_contexts = []
    for file_id in file_ids:
        if file_id in file_storage:
            file_data = file_storage[file_id]
            filename = file_data.get("filename", "unknown")
            markdown = file_data.get("markdown", "")

            if markdown:
                file_contexts.append(f"### æ–‡ä»¶: {filename}\n\n{markdown}")

    if not file_contexts:
        return message

    # æ„å»ºå®Œæ•´æ¶ˆæ¯
    context_text = "\n\n---\n\n".join(file_contexts)
    full_message = f"""è¯·ç»“åˆä»¥ä¸‹æ–‡ä»¶å†…å®¹å’Œç”¨æˆ·é—®é¢˜è¿›è¡Œè§£ç­”ï¼š

{context_text}

---

ç”¨æˆ·é—®é¢˜ï¼š{message}"""

    return full_message


def _extract_final_message(result) -> str:
    """
    ä»ç»“æœä¸­æå–æœ€ç»ˆæ¶ˆæ¯

    å‚æ•°:
        result: æ™ºèƒ½ä½“è¿è¡Œç»“æœ

    è¿”å›:
        æœ€ç»ˆæ¶ˆæ¯å­—ç¬¦ä¸²
    """
    if not result.messages:
        return "æœªç”Ÿæˆå“åº”"

    # ä»åå¾€å‰æŸ¥æ‰¾ç¬¬ä¸€ä¸ªæœ‰æ•ˆæ¶ˆæ¯
    for msg in reversed(result.messages):
        if hasattr(msg, 'content') and isinstance(msg.content, str):
            return msg.content

    return "æœªç”Ÿæˆå“åº”"



@router.get("/")
async def root():
    """æ ¹ç«¯ç‚¹"""
    return {
        "message": "AutoGen èŠå¤© API",
        "version": "1.0.0",
        "status": "running"
    }


@router.get("/health", response_model=HealthResponse)
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    session_service = get_session_service()
    session_count = await session_service.get_session_count()

    return HealthResponse(
        status="healthy",
        agent_initialized=True,
        session_count=session_count
    )


@router.post("/api/chat/stream")
async def chat_stream(request: ChatRequest):
    """
    ä½¿ç”¨ SSE çš„æµå¼èŠå¤©å“åº”ï¼ˆæ”¯æŒä¼šè¯éš”ç¦»ï¼‰

    å‚æ•°:
        request: åŒ…å«æ¶ˆæ¯çš„èŠå¤©è¯·æ±‚

    è¿”å›:
        åŒ…å« SSE æ ¼å¼æ•°æ®çš„ StreamingResponse
    """
    if not request.message:
        raise HTTPException(status_code=400, detail="æ¶ˆæ¯ä¸èƒ½ä¸ºç©º")

    # æ„å»ºåŒ…å«æ–‡ä»¶ä¸Šä¸‹æ–‡çš„æ¶ˆæ¯
    from .utils import build_message_with_file_context
    message_with_context = build_message_with_file_context(request.message, request.file_ids)

    # è·å–æœåŠ¡å®ä¾‹
    session_service = get_session_service()
    stream_service = get_stream_service()

    # è·å–æˆ–åˆ›å»ºä¼šè¯ï¼ˆæ¯ä¸ª conversation_id å¯¹åº”ä¸€ä¸ªç‹¬ç«‹çš„æ™ºèƒ½ä½“ï¼‰
    session = await session_service.get_or_create_session(request.conversation_id)

    # å¢åŠ æ¶ˆæ¯è®¡æ•°
    session.increment_message_count()

    # ä»ä¼šè¯çš„æ™ºèƒ½ä½“è·å–äº‹ä»¶æµ
    async def get_event_stream():
        async for event in session.agent.run_stream(task=message_with_context):
            yield event

    # å¤„ç†æµå¼å“åº”ï¼ˆä½¿ç”¨åŸå§‹ç”¨æˆ·æ¶ˆæ¯è®¡ç®— tokenï¼‰
    sse_stream = stream_service.process_stream(get_event_stream(), request.message)

    return StreamingResponse(
        sse_stream,
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # åœ¨ nginx ä¸­ç¦ç”¨ç¼“å†²
            "X-Session-ID": session.session_id,  # è¿”å›ä¼šè¯ ID
        }
    )


@router.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    éæµå¼èŠå¤©ç«¯ç‚¹ï¼ˆæ”¯æŒä¼šè¯éš”ç¦»ï¼‰

    å‚æ•°:
        request: åŒ…å«æ¶ˆæ¯çš„èŠå¤©è¯·æ±‚

    è¿”å›:
        åŒ…å«å®Œæ•´æ¶ˆæ¯çš„ ChatResponse
    """
    if not request.message:
        raise HTTPException(status_code=400, detail="æ¶ˆæ¯ä¸èƒ½ä¸ºç©º")

    # è·å–æœåŠ¡å®ä¾‹
    session_service = get_session_service()

    # è·å–æˆ–åˆ›å»ºä¼šè¯
    session = await session_service.get_or_create_session(request.conversation_id)

    # å¢åŠ æ¶ˆæ¯è®¡æ•°
    session.increment_message_count()

    try:
        # è¿è¡Œä¼šè¯çš„æ™ºèƒ½ä½“
        result = await session.agent.run(task=request.message)

        # æå–æœ€ç»ˆå“åº”
        from .utils import extract_final_message
        final_message = extract_final_message(result)

        return ChatResponse(
            message=final_message,
            conversation_id=session.session_id,
            status="success"
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/api/sessions")
async def list_sessions():
    """
    åˆ—å‡ºæ‰€æœ‰ä¼šè¯

    è¿”å›:
        ä¼šè¯åˆ—è¡¨
    """
    session_service = get_session_service()
    sessions = await session_service.list_sessions()

    return {
        "sessions": sessions,
        "total": len(sessions)
    }


@router.get("/api/sessions/{session_id}")
async def get_session_info(session_id: str):
    """
    è·å–ä¼šè¯ä¿¡æ¯

    å‚æ•°:
        session_id: ä¼šè¯ ID

    è¿”å›:
        ä¼šè¯ä¿¡æ¯
    """
    session_service = get_session_service()
    session_info = await session_service.get_session_info(session_id)

    if not session_info:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    return session_info


@router.delete("/api/sessions/{session_id}")
async def delete_session(session_id: str):
    """
    åˆ é™¤ä¼šè¯

    å‚æ•°:
        session_id: ä¼šè¯ ID

    è¿”å›:
        åˆ é™¤ç»“æœ
    """
    session_service = get_session_service()
    success = await session_service.delete_session(session_id)

    if not success:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    return {
        "message": "ä¼šè¯å·²åˆ é™¤",
        "session_id": session_id
    }



@router.post("/api/team-chat/stream")
async def team_chat_stream(request: ChatRequest):
    """
    æµ‹è¯•ç”¨ä¾‹å›¢é˜Ÿæ¨¡å¼çš„æµå¼èŠå¤©å“åº”

    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. æ–°å¯¹è¯ï¼šä¸ä¼  conversation_idï¼Œåˆ›å»ºæ–°çš„å›¢é˜Ÿä¼šè¯
    2. ç»§ç»­å¯¹è¯ï¼šä¼  conversation_id å’Œ is_feedback=Trueï¼Œç»§ç»­ä¹‹å‰çš„ä¼šè¯

    å‚æ•°:
        request: åŒ…å«æ¶ˆæ¯çš„èŠå¤©è¯·æ±‚

    è¿”å›:
        åŒ…å« SSE æ ¼å¼æ•°æ®çš„ StreamingResponse
    """
    if not request.message:
        raise HTTPException(status_code=400, detail="æ¶ˆæ¯ä¸èƒ½ä¸ºç©º")

    # å¯¼å…¥æœåŠ¡
    from services.ai_service import TestCasesTeamAIService
    from services.team_stream_service import TeamStreamService
    from services.team_session_service import get_team_session_service

    # è·å–ä¼šè¯æœåŠ¡
    session_service = get_team_session_service()

    # åˆå§‹åŒ–å˜é‡
    conversation_id = None
    team_service = None
    feedback_message = None

    # åˆ¤æ–­æ˜¯æ–°å¯¹è¯è¿˜æ˜¯ç»§ç»­å¯¹è¯
    if request.is_feedback and request.conversation_id:
        # ç»§ç»­å¯¹è¯ï¼šä»ä¼šè¯ä¸­æ¢å¤å›¢é˜Ÿ
        session = session_service.get_session(request.conversation_id)
        if not session:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        if not session.waiting_for_feedback:
            raise HTTPException(status_code=400, detail="å½“å‰ä¼šè¯ä¸åœ¨ç­‰å¾…åé¦ˆçŠ¶æ€")

        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦åŒæ„ï¼ˆç©ºæ¶ˆæ¯æˆ–åŒ…å«"åŒæ„"/"APPROVE"ï¼‰
        is_user_approved = not request.message.strip() or "åŒæ„" in request.message or "APPROVE" in request.message.upper()

        if is_user_approved:
            # ç”¨æˆ·åŒæ„ï¼Œè°ƒç”¨ Optimizer ç»™å‡ºæœ€ç»ˆå›ç­”
            conversation_id = request.conversation_id

            # æ¸…ç†æ—§çš„å›¢é˜Ÿå®ä¾‹
            old_team_service = _get_cached_team_service(conversation_id)
            if old_team_service:
                await old_team_service.cleanup()
                _remove_cached_team_service(conversation_id)

            # æ·»åŠ ç”¨æˆ·åŒæ„åˆ°ä¼šè¯
            session_service.add_message(conversation_id, "user", "åŒæ„")

            # è·å–å¯¹è¯å†å²
            history = session_service.get_conversation_history(conversation_id)

            # æ„å»ºç»™ Optimizer çš„æ¶ˆæ¯
            history_text = "\n\n".join([
                f"{'ç”¨æˆ·' if msg['role'] == 'user' else msg['role']}: {msg['content']}"
                for msg in history[:-1]  # æ’é™¤æœ€åä¸€æ¡ï¼ˆ"åŒæ„"ï¼‰
            ])

            optimizer_message = f"å¯¹è¯å†å²ï¼š\n{history_text}\n\nç”¨æˆ·å·²åŒæ„ä»¥ä¸Šæ–¹æ¡ˆã€‚è¯·ä½œä¸ºæµ‹è¯•ç”¨ä¾‹ä¼˜åŒ–å™¨ï¼Œç»“åˆç”Ÿæˆå™¨å’Œè¯„å®¡å‘˜çš„æ„è§ï¼Œç»™å‡ºæœ€ç»ˆä¼˜åŒ–çš„æµ‹è¯•ç”¨ä¾‹ã€‚"

            # åˆ›å»ºæ–°çš„å›¢é˜Ÿå®ä¾‹ï¼ˆåªåŒ…å« Optimizerï¼‰
            team_service = TestCasesTeamAIService(settings)
            await team_service.initialize(specific_agent="TestCase_Optimizer")

            # ç¼“å­˜å›¢é˜Ÿå®ä¾‹
            _cache_team_service(conversation_id, team_service)

            # è®¾ç½®ä¸ºæœ€ç»ˆå›ç­”æ¨¡å¼
            feedback_message = optimizer_message

            print(f"âœ… ç”¨æˆ·åŒæ„ï¼Œè°ƒç”¨ Optimizer ç»™å‡ºæœ€ç»ˆå›ç­”")

            # ç»§ç»­æ‰§è¡Œåç»­æµç¨‹ï¼ˆè¿è¡Œ Optimizerï¼‰
        else:
            # ç”¨æˆ·æä¾›äº†åé¦ˆï¼Œåˆ›å»ºæ–°çš„å›¢é˜Ÿå®ä¾‹ç»§ç»­å¯¹è¯
            conversation_id = request.conversation_id

            # æ¸…ç†æ—§çš„å›¢é˜Ÿå®ä¾‹
            old_team_service = _get_cached_team_service(conversation_id)
            if old_team_service:
                await old_team_service.cleanup()
                _remove_cached_team_service(conversation_id)

            # æ·»åŠ ç”¨æˆ·åé¦ˆåˆ°ä¼šè¯
            session_service.add_message(conversation_id, "user", request.message)

            # è§£æç›®æ ‡æ™ºèƒ½ä½“ï¼ˆå¦‚æœç”¨æˆ·ä½¿ç”¨ @ æåŠï¼‰
            target_agent = _parse_target_agent(request.message)

            # æ„å»ºåé¦ˆæ¶ˆæ¯ï¼ˆåŒ…å«å¯¹è¯å†å²ï¼‰
            history = session_service.get_conversation_history(conversation_id)

            # æ„å»ºåŒ…å«å†å²çš„æ¶ˆæ¯
            history_text = "\n\n".join([
                f"{'ç”¨æˆ·' if msg['role'] == 'user' else msg['role']}: {msg['content']}"
                for msg in history[:-1]  # æ’é™¤æœ€åä¸€æ¡ï¼ˆå½“å‰åé¦ˆï¼‰
            ])

            if target_agent == "all":
                # ç”¨æˆ·é€‰æ‹© @allï¼Œé‡æ–°è¿è¡Œ Generator â†’ Reviewer æµç¨‹
                feedback_message = f"å¯¹è¯å†å²ï¼š\n{history_text}\n\nç”¨æˆ·åé¦ˆï¼ˆ@allï¼‰: {request.message}"

                # åˆ›å»ºæ–°çš„å›¢é˜ŸæœåŠ¡å®ä¾‹ï¼ˆGenerator â†’ Reviewerï¼‰
                team_service = TestCasesTeamAIService(settings)
                await team_service.initialize()  # é»˜è®¤åŒ…å« Generator å’Œ Reviewer

                print(f"ğŸ”„ ç»§ç»­å¯¹è¯ {conversation_id}ï¼Œ@all é‡æ–°è¿è¡Œ Generator â†’ Reviewer æµç¨‹")
            elif target_agent:
                # ç”¨æˆ·æŒ‡å®šäº†ç‰¹å®šæ™ºèƒ½ä½“ï¼Œåªè¿è¡Œè¯¥æ™ºèƒ½ä½“
                feedback_message = f"å¯¹è¯å†å²ï¼š\n{history_text}\n\nç”¨æˆ·åé¦ˆï¼ˆ@{target_agent}ï¼‰: {request.message}"

                # åˆ›å»ºæ–°çš„å›¢é˜ŸæœåŠ¡å®ä¾‹ï¼ˆåªåŒ…å«æŒ‡å®šçš„æ™ºèƒ½ä½“ï¼‰
                team_service = TestCasesTeamAIService(settings)
                await team_service.initialize(specific_agent=target_agent)

                print(f"ğŸ¯ ç»§ç»­å¯¹è¯ {conversation_id}ï¼ŒæŒ‡å®šæ™ºèƒ½ä½“: {target_agent}")
            else:
                # ç”¨æˆ·æœªæŒ‡å®šæ™ºèƒ½ä½“ï¼Œé‡å¤ Generator â†’ Reviewer æµç¨‹
                feedback_message = f"å¯¹è¯å†å²ï¼š\n{history_text}\n\nç”¨æˆ·åé¦ˆ: {request.message}"

                # åˆ›å»ºæ–°çš„å›¢é˜ŸæœåŠ¡å®ä¾‹ï¼ˆGenerator â†’ Reviewerï¼‰
                team_service = TestCasesTeamAIService(settings)
                await team_service.initialize()  # é»˜è®¤åŒ…å« Generator å’Œ Reviewer

                print(f"ğŸ“ ç»§ç»­å¯¹è¯ {conversation_id}ï¼Œé‡å¤ Generator â†’ Reviewer æµç¨‹")

            # æ›´æ–°ç¼“å­˜
            _cache_team_service(conversation_id, team_service)

    else:
        # æ–°å¯¹è¯ï¼šåˆ›å»ºæ–°çš„å›¢é˜Ÿå’Œä¼šè¯
        conversation_id = session_service.create_session()

        # åˆ›å»ºå›¢é˜ŸæœåŠ¡å®ä¾‹
        team_service = TestCasesTeamAIService(settings)
        await team_service.initialize()

        # ç¼“å­˜å›¢é˜Ÿå®ä¾‹
        _cache_team_service(conversation_id, team_service)

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¼šè¯
        session_service.add_message(conversation_id, "user", request.message)

        feedback_message = request.message

        print(f"ğŸ†• åˆ›å»ºæ–°å¯¹è¯ {conversation_id}")

    # æ„å»ºåŒ…å«æ–‡ä»¶ä¸Šä¸‹æ–‡çš„æ¶ˆæ¯
    from .utils import build_message_with_file_context
    message_with_context = build_message_with_file_context(feedback_message, request.file_ids)

    # åˆ›å»ºå›¢é˜ŸæµæœåŠ¡
    from services.team_stream_service import TeamStreamService
    team_stream_service = TeamStreamService()

    # ä»å›¢é˜Ÿè·å–äº‹ä»¶æµ
    async def get_event_stream():
        try:
            # æ— è®ºæ˜¯æ–°å¯¹è¯è¿˜æ˜¯ç»§ç»­å¯¹è¯ï¼Œéƒ½ä¼ å…¥æ¶ˆæ¯
            # AutoGen çš„ RoundRobinGroupChat ä¼šè‡ªåŠ¨ç»´æŠ¤å¯¹è¯å†å²
            async for event in team_service.run_stream(message=message_with_context):
                yield event
        except Exception as e:
            print(f"âŒ å›¢é˜Ÿæµé”™è¯¯: {e}")
            raise

    # å¤„ç†æµå¼å“åº”
    sse_stream = team_stream_service.process_stream(get_event_stream(), request.message)

    # åœ¨æµç»“æŸåæ›´æ–°ä¼šè¯çŠ¶æ€
    async def sse_stream_with_session_update():
        current_conversation_id = conversation_id
        try:
            async for chunk in sse_stream:
                yield chunk

            # ä¿å­˜æ™ºèƒ½ä½“çš„å›ç­”åˆ°ä¼šè¯å†å²
            for agent_name, response in team_stream_service.agent_responses.items():
                if response:  # åªä¿å­˜éç©ºå›ç­”
                    session_service.add_message(current_conversation_id, agent_name, response)
                    print(f"ğŸ’¾ ä¿å­˜ {agent_name} çš„å›ç­”åˆ°ä¼šè¯å†å²")

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç­‰å¾…åé¦ˆ
            if team_stream_service.waiting_for_feedback:
                session_service.set_waiting_for_feedback(
                    current_conversation_id,
                    True,
                    team_stream_service.feedback_agent
                )
                print(f"â¸ï¸ ä¼šè¯ {current_conversation_id} ç­‰å¾…ç”¨æˆ·åé¦ˆ")
            else:
                # å¯¹è¯ç»“æŸï¼Œæ¸…ç†èµ„æº
                session_service.set_waiting_for_feedback(current_conversation_id, False)
                _remove_cached_team_service(current_conversation_id)
                await team_service.cleanup()
                print(f"âœ… ä¼šè¯ {current_conversation_id} å·²å®Œæˆ")
        except Exception as e:
            print(f"âŒ SSE æµé”™è¯¯: {e}")
            # æ¸…ç†èµ„æº
            _remove_cached_team_service(current_conversation_id)
            await team_service.cleanup()
            raise

    return StreamingResponse(
        sse_stream_with_session_update(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
            "X-Team-Mode": "true",
            "X-Conversation-ID": conversation_id,
        }
    )


@router.post("/api/convert/markdown", response_model=MarkdownConvertResponse)
async def convert_to_markdown(
    file: UploadFile = File(..., description="è¦è½¬æ¢çš„æ–‡ä»¶"),
    use_llm: bool = Form(default=None, description="æ˜¯å¦ä½¿ç”¨ LLM æå‡è½¬æ¢ç²¾åº¦"),
    force_ocr: bool = Form(default=None, description="æ˜¯å¦å¼ºåˆ¶å¯¹æ‰€æœ‰å†…å®¹è¿›è¡Œ OCR"),
    disable_image_extraction: bool = Form(default=None, description="æ˜¯å¦ç¦ç”¨å›¾ç‰‡æå–"),
    page_range: Optional[str] = Form(default=None, description="é¡µé¢èŒƒå›´ï¼Œä¾‹å¦‚: '0,5-10,20'"),
    output_format: str = Form(default=None, description="è¾“å‡ºæ ¼å¼"),
    llm_api_key: Optional[str] = Form(default=None, description="LLM API å¯†é’¥"),
    llm_base_url: Optional[str] = Form(default=None, description="LLM API åŸºç¡€ URL"),
    llm_model: Optional[str] = Form(default=None, description="LLM æ¨¡å‹åç§°"),
):
    """
    å°†ä¸Šä¼ çš„æ–‡ä»¶è½¬æ¢ä¸º Markdown æ ¼å¼

    æ”¯æŒçš„æ–‡ä»¶æ ¼å¼:
    - PDF (.pdf)
    - å›¾ç‰‡ (.png, .jpg, .jpeg, .gif, .bmp, .tiff)
    - PowerPoint (.pptx, .ppt)
    - Word (.docx, .doc)
    - Excel (.xlsx, .xls)
    - HTML (.html, .htm)
    - EPUB (.epub)

    å‚æ•°:
        file: ä¸Šä¼ çš„æ–‡ä»¶
        use_llm: æ˜¯å¦ä½¿ç”¨ LLM æå‡è½¬æ¢ç²¾åº¦
        force_ocr: æ˜¯å¦å¼ºåˆ¶å¯¹æ‰€æœ‰å†…å®¹è¿›è¡Œ OCR
        disable_image_extraction: æ˜¯å¦ç¦ç”¨å›¾ç‰‡æå–
        page_range: é¡µé¢èŒƒå›´
        output_format: è¾“å‡ºæ ¼å¼
        llm_api_key: LLM API å¯†é’¥ï¼ˆå¦‚æœä½¿ç”¨ LLMï¼‰
        llm_base_url: LLM API åŸºç¡€ URLï¼ˆå¦‚æœä½¿ç”¨ LLMï¼‰
        llm_model: LLM æ¨¡å‹åç§°ï¼ˆå¦‚æœä½¿ç”¨ LLMï¼‰

    è¿”å›:
        MarkdownConvertResponse: åŒ…å«è½¬æ¢ç»“æœçš„å“åº”
    """
    from services.markdown_converter_service import MarkdownConverterService

    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        file_bytes = await file.read()

        # ä½¿ç”¨é…ç½®æ–‡ä»¶çš„é»˜è®¤å€¼ï¼Œå¦‚æœå‚æ•°ä¸º None
        final_use_llm = use_llm if use_llm is not None else settings.markdown_use_llm
        final_force_ocr = force_ocr if force_ocr is not None else settings.markdown_force_ocr
        final_disable_image = disable_image_extraction if disable_image_extraction is not None else settings.markdown_disable_image_extraction
        final_output_format = output_format if output_format is not None else settings.markdown_output_format

        # LLM é…ç½®ä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶
        final_llm_api_key = llm_api_key or settings.markdown_llm_api_key
        final_llm_base_url = llm_base_url or settings.markdown_llm_base_url
        final_llm_model = llm_model or settings.markdown_llm_model
        final_llm_service = settings.markdown_llm_service if final_use_llm and final_llm_api_key else None

        # åˆ›å»ºè½¬æ¢æœåŠ¡
        converter_service = MarkdownConverterService(
            use_llm=final_use_llm,
            force_ocr=final_force_ocr,
            disable_image_extraction=final_disable_image,
            output_format=final_output_format,
            llm_service=final_llm_service,
            llm_api_key=final_llm_api_key,
            llm_base_url=final_llm_base_url,
            llm_model=final_llm_model,
        )

        # æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ
        if not converter_service.is_supported_file(file.filename):
            supported_formats = converter_service.get_supported_formats()
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚æ”¯æŒçš„æ ¼å¼: {', '.join(supported_formats)}"
            )

        # è½¬æ¢æ–‡ä»¶
        result = await converter_service.convert_file_bytes(
            file_bytes=file_bytes,
            filename=file.filename,
            page_range=page_range
        )

        return MarkdownConvertResponse(**result)

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è½¬æ¢å¤±è´¥: {str(e)}")


@router.get("/api/convert/supported-formats")
async def get_supported_formats():
    """
    è·å–æ”¯æŒçš„æ–‡ä»¶æ ¼å¼åˆ—è¡¨

    è¿”å›:
        æ”¯æŒçš„æ–‡ä»¶æ ¼å¼åˆ—è¡¨
    """
    from services.markdown_converter_service import MarkdownConverterService

    converter_service = MarkdownConverterService()
    supported_formats = converter_service.get_supported_formats()

    return {
        "supported_formats": supported_formats,
        "total": len(supported_formats)
    }


@router.post("/api/convert/markdown/batch", response_model=BatchMarkdownConvertResponse)
async def convert_multiple_to_markdown(
    files: list[UploadFile] = File(..., description=f"è¦è½¬æ¢çš„å¤šä¸ªæ–‡ä»¶ï¼ˆæœ€å¤š{settings.markdown_max_batch_files}ä¸ªï¼Œæ¯ä¸ªæœ€å¤§{settings.markdown_max_file_size_mb}MBï¼‰"),
    use_llm: bool = Form(default=None, description="æ˜¯å¦ä½¿ç”¨ LLM æå‡è½¬æ¢ç²¾åº¦"),
    force_ocr: bool = Form(default=None, description="æ˜¯å¦å¼ºåˆ¶å¯¹æ‰€æœ‰å†…å®¹è¿›è¡Œ OCR"),
    disable_image_extraction: bool = Form(default=None, description="æ˜¯å¦ç¦ç”¨å›¾ç‰‡æå–"),
    page_range: Optional[str] = Form(default=None, description="é¡µé¢èŒƒå›´ï¼Œä¾‹å¦‚: '0,5-10,20'"),
    output_format: str = Form(default=None, description="è¾“å‡ºæ ¼å¼"),
    max_concurrent: int = Form(default=None, description="æœ€å¤§å¹¶å‘è½¬æ¢æ•°"),
    llm_api_key: Optional[str] = Form(default=None, description="LLM API å¯†é’¥"),
    llm_base_url: Optional[str] = Form(default=None, description="LLM API åŸºç¡€ URL"),
    llm_model: Optional[str] = Form(default=None, description="LLM æ¨¡å‹åç§°"),
):
    """
    æ‰¹é‡è½¬æ¢å¤šä¸ªæ–‡ä»¶ä¸º Markdown æ ¼å¼ï¼ˆå¹¶å‘å¤„ç†ï¼‰

    æ”¯æŒçš„æ–‡ä»¶æ ¼å¼:
    - PDF (.pdf)
    - å›¾ç‰‡ (.png, .jpg, .jpeg, .gif, .bmp, .tiff)
    - PowerPoint (.pptx, .ppt)
    - Word (.docx, .doc)
    - Excel (.xlsx, .xls)
    - HTML (.html, .htm)
    - EPUB (.epub)

    å‚æ•°:
        files: ä¸Šä¼ çš„å¤šä¸ªæ–‡ä»¶
        use_llm: æ˜¯å¦ä½¿ç”¨ LLM æå‡è½¬æ¢ç²¾åº¦
        force_ocr: æ˜¯å¦å¼ºåˆ¶å¯¹æ‰€æœ‰å†…å®¹è¿›è¡Œ OCR
        disable_image_extraction: æ˜¯å¦ç¦ç”¨å›¾ç‰‡æå–
        page_range: é¡µé¢èŒƒå›´
        output_format: è¾“å‡ºæ ¼å¼
        max_concurrent: æœ€å¤§å¹¶å‘è½¬æ¢æ•°ï¼ˆé»˜è®¤: 3ï¼Œå»ºè®®ä¸è¶…è¿‡ 5ï¼‰
        llm_api_key: LLM API å¯†é’¥ï¼ˆå¦‚æœä½¿ç”¨ LLMï¼‰
        llm_base_url: LLM API åŸºç¡€ URLï¼ˆå¦‚æœä½¿ç”¨ LLMï¼‰
        llm_model: LLM æ¨¡å‹åç§°ï¼ˆå¦‚æœä½¿ç”¨ LLMï¼‰

    è¿”å›:
        BatchMarkdownConvertResponse: åŒ…å«æ‰€æœ‰æ–‡ä»¶è½¬æ¢ç»“æœçš„å“åº”
    """
    from services.markdown_converter_service import MarkdownConverterService

    try:
        # æ£€æŸ¥æ–‡ä»¶æ•°é‡
        if len(files) == 0:
            raise HTTPException(status_code=400, detail="è‡³å°‘éœ€è¦ä¸Šä¼ ä¸€ä¸ªæ–‡ä»¶")

        if len(files) > settings.markdown_max_batch_files:
            raise HTTPException(
                status_code=400,
                detail=f"å•æ¬¡æœ€å¤šæ”¯æŒ {settings.markdown_max_batch_files} ä¸ªæ–‡ä»¶"
            )

        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        MAX_FILE_SIZE = settings.markdown_max_file_size_mb * 1024 * 1024
        for file in files:
            # è¯»å–æ–‡ä»¶å¤§å°
            file.file.seek(0, 2)  # ç§»åŠ¨åˆ°æ–‡ä»¶æœ«å°¾
            file_size = file.file.tell()
            file.file.seek(0)  # é‡ç½®åˆ°æ–‡ä»¶å¼€å¤´

            if file_size > MAX_FILE_SIZE:
                raise HTTPException(
                    status_code=400,
                    detail=f"æ–‡ä»¶ {file.filename} å¤§å°è¶…è¿‡é™åˆ¶ï¼ˆæœ€å¤§ {settings.markdown_max_file_size_mb}MBï¼‰"
                )

        # ä½¿ç”¨é…ç½®æ–‡ä»¶çš„é»˜è®¤å€¼
        final_use_llm = use_llm if use_llm is not None else settings.markdown_use_llm
        final_force_ocr = force_ocr if force_ocr is not None else settings.markdown_force_ocr
        final_disable_image = disable_image_extraction if disable_image_extraction is not None else settings.markdown_disable_image_extraction
        final_output_format = output_format if output_format is not None else settings.markdown_output_format
        final_max_concurrent = max_concurrent if max_concurrent is not None else settings.markdown_max_concurrent

        # LLM é…ç½®
        final_llm_api_key = llm_api_key or settings.markdown_llm_api_key
        final_llm_base_url = llm_base_url or settings.markdown_llm_base_url
        final_llm_model = llm_model or settings.markdown_llm_model
        final_llm_service = settings.markdown_llm_service if final_use_llm and final_llm_api_key else None

        # åˆ›å»ºè½¬æ¢æœåŠ¡
        converter_service = MarkdownConverterService(
            use_llm=final_use_llm,
            force_ocr=final_force_ocr,
            disable_image_extraction=final_disable_image,
            output_format=final_output_format,
            llm_service=final_llm_service,
            llm_api_key=final_llm_api_key,
            llm_base_url=final_llm_base_url,
            llm_model=final_llm_model,
        )

        # è¯»å–æ‰€æœ‰æ–‡ä»¶å†…å®¹
        files_data = []
        for file in files:
            # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
            if not converter_service.is_supported_file(file.filename):
                # æ·»åŠ å¤±è´¥ç»“æœ
                files_data.append((None, file.filename, "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"))
            else:
                file_bytes = await file.read()
                files_data.append((file_bytes, file.filename, None))

        # åˆ†ç¦»æœ‰æ•ˆæ–‡ä»¶å’Œæ— æ•ˆæ–‡ä»¶
        valid_files = [(fb, fn) for fb, fn, err in files_data if err is None]
        invalid_files = [(fn, err) for fb, fn, err in files_data if err is not None]

        # å¹¶å‘è½¬æ¢æœ‰æ•ˆæ–‡ä»¶
        results = []

        if valid_files:
            conversion_results = await converter_service.convert_multiple_file_bytes(
                files_data=valid_files,
                page_range=page_range,
                max_concurrent=final_max_concurrent
            )
            results.extend(conversion_results)

        # æ·»åŠ æ— æ•ˆæ–‡ä»¶çš„ç»“æœ
        for filename, error in invalid_files:
            results.append({
                "success": False,
                "message": error,
                "markdown": "",
                "metadata": {},
                "images": {},
                "filename": filename
            })

        # ä¸ºæ¯ä¸ªæˆåŠŸçš„æ–‡ä»¶ç”Ÿæˆ ID å¹¶å­˜å‚¨å†…å®¹
        for result in results:
            if result.get("success", False):
                file_id = str(uuid.uuid4())
                result["file_id"] = file_id

                # å­˜å‚¨æ–‡ä»¶å†…å®¹åˆ°å†…å­˜ï¼ˆåŒ…å«æ–‡ä»¶åå’Œ markdown å†…å®¹ï¼‰
                file_storage[file_id] = {
                    "filename": result.get("filename", "unknown"),
                    "markdown": result.get("markdown", ""),
                    "metadata": result.get("metadata", {})
                }
            else:
                result["file_id"] = None

        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results if r.get("success", False))
        failed_count = len(results) - success_count

        return BatchMarkdownConvertResponse(
            total=len(results),
            success_count=success_count,
            failed_count=failed_count,
            results=results
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡è½¬æ¢å¤±è´¥: {str(e)}")



@router.post("/api/image-analysis/stream")
async def image_analysis_stream(
    image: Optional[UploadFile] = File(None, description="ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶"),
    session_id: Optional[str] = Form(None, description="ä¼šè¯ ID"),
    image_url: Optional[str] = Form(None, description="å›¾ç‰‡ URL"),
    web_url: Optional[str] = Form(None, description="å›¾ç‰‡æ‰€åœ¨é¡µé¢çš„ URL"),
    test_description: Optional[str] = Form(None, description="æµ‹è¯•åœºæ™¯æè¿°"),
    additional_context: Optional[str] = Form(None, description="é™„åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯"),
    target_url: Optional[str] = Form(None, description="ç›®æ ‡é¡µé¢ URL")
):
    """
    å›¾ç‰‡åˆ†ææµå¼ APIï¼ˆæ”¯æŒ SSEï¼‰

    æ”¯æŒä¸¤ç§æ–¹å¼æä¾›å›¾ç‰‡ï¼š
    1. ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶ï¼ˆimage å‚æ•°ï¼‰
    2. æä¾›å›¾ç‰‡ URLï¼ˆimage_url å‚æ•°ï¼‰

    è¿”å›æµå¼äº‹ä»¶ï¼ŒåŒ…æ‹¬ï¼š
    - agent_start: æ™ºèƒ½ä½“å¼€å§‹å·¥ä½œ
    - agent_message: æ™ºèƒ½ä½“æ¶ˆæ¯
    - agent_done: æ™ºèƒ½ä½“å®Œæˆ
    - done: åˆ†æå®Œæˆ
    - error: é”™è¯¯ä¿¡æ¯
    """
    from services.image_analysis_stream_service import ImageAnalysisStreamService

    try:
        # ç”Ÿæˆä¼šè¯ ID
        if not session_id:
            session_id = f"img_{uuid.uuid4().hex[:12]}"

        print(f"\n{'='*60}")
        print(f"ğŸ“¸ å›¾ç‰‡åˆ†æè¯·æ±‚")
        print(f"{'='*60}")
        print(f"ä¼šè¯ ID: {session_id}")

        # å¤„ç†å›¾ç‰‡æ•°æ®
        image_data = None
        if image:
            # è¯»å–ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶
            content = await image.read()
            image_data = base64.b64encode(content).decode('utf-8')
            print(f"å›¾ç‰‡æ–‡ä»¶: {image.filename} ({len(content)} å­—èŠ‚)")
        elif image_url:
            print(f"å›¾ç‰‡ URL: {image_url}")
        else:
            raise HTTPException(status_code=400, detail="å¿…é¡»æä¾›å›¾ç‰‡æ–‡ä»¶æˆ–å›¾ç‰‡ URL")

        if web_url:
            print(f"é¡µé¢ URL: {web_url}")
        if test_description:
            print(f"æµ‹è¯•æè¿°: {test_description}")

        # åˆ›å»ºæµå¼æœåŠ¡
        stream_service = ImageAnalysisStreamService()

        # åˆ›å»ºå›¾ç‰‡åˆ†æå›¢é˜Ÿå¹¶åˆå§‹åŒ–
        from agents.image_analyzer_team import ImageAnalyzerTeam
        analyzer_team = ImageAnalyzerTeam(settings)
        await analyzer_team.initialize()

        # æ‰§è¡Œæµå¼åˆ†æ
        event_stream = analyzer_team.analyze_image_stream(
            session_id=session_id,
            image_data=image_data,
            image_url=image_url,
            web_url=web_url,
            test_description=test_description,
            additional_context=additional_context,
            target_url=target_url
        )

        # å¤„ç†äº‹ä»¶æµå¹¶ç”Ÿæˆ SSE å“åº”
        async def generate_sse():
            async for sse_message in stream_service.process_stream(event_stream, session_id):
                yield sse_message

        return StreamingResponse(
            generate_sse(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Session-ID": session_id,
            }
        )

    except Exception as e:
        print(f"âŒ å›¾ç‰‡åˆ†æé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}")


@router.post("/api/image-analysis", response_model=ImageAnalysisResponse)
async def image_analysis(
    image: Optional[UploadFile] = File(None, description="ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶"),
    session_id: Optional[str] = Form(None, description="ä¼šè¯ ID"),
    image_url: Optional[str] = Form(None, description="å›¾ç‰‡ URL"),
    web_url: Optional[str] = Form(None, description="å›¾ç‰‡æ‰€åœ¨é¡µé¢çš„ URL"),
    test_description: Optional[str] = Form(None, description="æµ‹è¯•åœºæ™¯æè¿°"),
    additional_context: Optional[str] = Form(None, description="é™„åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯"),
    target_url: Optional[str] = Form(None, description="ç›®æ ‡é¡µé¢ URL")
):
    """
    å›¾ç‰‡åˆ†æéæµå¼ API

    æ”¯æŒä¸¤ç§æ–¹å¼æä¾›å›¾ç‰‡ï¼š
    1. ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶ï¼ˆimage å‚æ•°ï¼‰
    2. æä¾›å›¾ç‰‡ URLï¼ˆimage_url å‚æ•°ï¼‰

    è¿”å›å®Œæ•´çš„åˆ†æç»“æœ
    """
    try:
        # ç”Ÿæˆä¼šè¯ ID
        if not session_id:
            session_id = f"img_{uuid.uuid4().hex[:12]}"

        print(f"\n{'='*60}")
        print(f"ğŸ“¸ å›¾ç‰‡åˆ†æè¯·æ±‚ï¼ˆéæµå¼ï¼‰")
        print(f"{'='*60}")
        print(f"ä¼šè¯ ID: {session_id}")

        # å¤„ç†å›¾ç‰‡æ•°æ®
        image_data = None
        if image:
            # è¯»å–ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶
            content = await image.read()
            image_data = base64.b64encode(content).decode('utf-8')
            print(f"å›¾ç‰‡æ–‡ä»¶: {image.filename} ({len(content)} å­—èŠ‚)")
        elif image_url:
            print(f"å›¾ç‰‡ URL: {image_url}")
        else:
            raise HTTPException(status_code=400, detail="å¿…é¡»æä¾›å›¾ç‰‡æ–‡ä»¶æˆ–å›¾ç‰‡ URL")

        # åˆ›å»ºå›¾ç‰‡åˆ†æå›¢é˜Ÿå¹¶åˆå§‹åŒ–
        from agents.image_analyzer_team import ImageAnalyzerTeam
        analyzer_team = ImageAnalyzerTeam(settings)
        await analyzer_team.initialize()

        # æ‰§è¡Œåˆ†æ
        results = await analyzer_team.analyze_image(
            session_id=session_id,
            image_data=image_data,
            image_url=image_url,
            web_url=web_url,
            test_description=test_description,
            additional_context=additional_context,
            target_url=target_url
        )

        # è¿”å›ç»“æœ
        return ImageAnalysisResponse(
            session_id=session_id,
            ui_analysis=results["ui_analysis"],
            interaction_analysis=results["interaction_analysis"],
            test_scenarios=results["test_scenarios"],
            chat_history=results["chat_history"],
            summary=results["summary"],
            status="success"
        )

    except Exception as e:
        print(f"âŒ å›¾ç‰‡åˆ†æé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}")

