"""
LLM æ¨¡å‹å®¢æˆ·ç«¯ç®¡ç†æ¨¡å—
æä¾›å„ç§ LLM æ¨¡å‹å®¢æˆ·ç«¯çš„åˆ›å»ºå’Œç®¡ç†åŠŸèƒ½
æ”¯æŒ UI è‡ªåŠ¨åŒ–ã€å›¾åƒåˆ†æç­‰å¤šç§åœºæ™¯
"""
from typing import Optional
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_core.models import ModelInfo
from config import Settings

# å…¨å±€æ¨¡å‹å®¢æˆ·ç«¯ç¼“å­˜
_deepseek_model_client: Optional[OpenAIChatCompletionClient] = None
_uitars_model_client: Optional[OpenAIChatCompletionClient] = None
_qwen_vl_least_client: Optional[OpenAIChatCompletionClient] = None


# defaultä¸ºdeepseek-chat
_default_model_client: Optional[OpenAIChatCompletionClient] = None


async def deepseek_model_client(settings: Optional[Settings] = None) -> OpenAIChatCompletionClient:
    """
    è·å– DeepSeek æ¨¡å‹å®¢æˆ·ç«¯ï¼Œç”¨äºé€šç”¨å¯¹è¯å’Œæ–‡æœ¬å¤„ç†

    å‚æ•°:
        settings: é…ç½®å®ä¾‹ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨å…¨å±€é…ç½®

    è¿”å›:
        OpenAIChatCompletionClient å®ä¾‹
    """
    global _deepseek_model_client
    if _deepseek_model_client is None:
        if settings is None:
            from config import settings as global_settings
            settings = global_settings

        # ä»é…ç½®ä¸­è·å– DeepSeek æ¨¡å‹ä¿¡æ¯
        deepseek_model = getattr(settings, 'deepseek_model', 'deepseek-chat')
        deepseek_api_key = getattr(settings, 'deepseek_api_key', settings.api_key)
        deepseek_base_url = getattr(settings, 'deepseek_base_url', settings.base_url)


        _deepseek_model_client = OpenAIChatCompletionClient(
            model=settings.model_name,
            api_key=settings.api_key,
            base_url=settings.base_url, 
            model_info={
                "vision": False,
                "function_calling": True,
                "json_output": True,
                "structured_output": True,
                "family": "deepseek",
                "multiple_system_messages": True,
            },
        )
        print(f"âœ… DeepSeek æ¨¡å‹å®¢æˆ·ç«¯å·²åˆ›å»ºæˆåŠŸ")

    return _deepseek_model_client


async def uitars_model_client(settings: Optional[Settings] = None) -> OpenAIChatCompletionClient:
    """
    è·å– UI-TARS æ¨¡å‹å®¢æˆ·ç«¯ï¼Œç”¨äº UI è‡ªåŠ¨åŒ–å’Œå›¾åƒåˆ†æ

    å‚æ•°:
        settings: é…ç½®å®ä¾‹ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨å…¨å±€é…ç½®

    è¿”å›:
        OpenAIChatCompletionClient å®ä¾‹
    """
    global _uitars_model_client

    if _uitars_model_client is None:
        if settings is None:
            from config import settings as global_settings
            settings = global_settings

        # ä»é…ç½®ä¸­è·å– UI-TARS æ¨¡å‹ä¿¡æ¯
        uitars_model = getattr(settings, 'uitars_model', 'gpt-4o')
        uitars_api_key = getattr(settings, 'uitars_api_key', settings.api_key)
        uitars_base_url = getattr(settings, 'uitars_base_url', settings.base_url)

        # è°ƒè¯•ä¿¡æ¯
        print(f"\nğŸ” UI-TARS æ¨¡å‹é…ç½®:")
        print(f"   æ¨¡å‹: {uitars_model}")
        print(f"   API Key: {uitars_api_key[:20]}...{uitars_api_key[-10:] if uitars_api_key and len(uitars_api_key) > 30 else uitars_api_key}")
        print(f"   Base URL: {uitars_base_url}")

        _uitars_model_client = OpenAIChatCompletionClient(
            model=uitars_model,
            api_key=uitars_api_key,
            base_url=uitars_base_url,
            model_info={
                "vision": True,
                "function_calling": True,
                "json_output": True,
                "structured_output": True,
                "family": "unknown",
                "multiple_system_messages": True,
            },
        )
        print(f"âœ… UI-TARS æ¨¡å‹å®¢æˆ·ç«¯å·²åˆ›å»ºæˆåŠŸ")

    return _uitars_model_client


async def qwen_vl_least_client(settings: Optional[Settings] = None) -> OpenAIChatCompletionClient:
    """
    è·å–åƒé—®è§†è§‰æ¨¡å‹ï¼Œç”¨äºå›¾åƒç†è§£å’Œåˆ†æ

    å‚æ•°:
        settings: é…ç½®å®ä¾‹ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨å…¨å±€é…ç½®

    è¿”å›:
        OpenAIChatCompletionClient å®ä¾‹
    """
    global _qwen_vl_least_client

    if _qwen_vl_least_client is None:
        if settings is None:
            from config import settings as global_settings
            settings = global_settings

        # ä»é…ç½®ä¸­è·å–è§†è§‰æ¨¡å‹ä¿¡æ¯
        qwen_vl_least_model = getattr(settings, 'qwen_vl_least_model', settings.model_name)
        qwen_vl_least_api_key = getattr(settings, 'qwen_vl_least_api_key', settings.api_key)
        qwen_vl_least_base_url = getattr(settings, 'qwen_vl_least_base_url', settings.base_url)

        _qwen_vl_least_client = OpenAIChatCompletionClient(
            model=qwen_vl_least_model,
            api_key=qwen_vl_least_api_key,
            base_url=qwen_vl_least_base_url,
            model_info={
                "vision": True,
                "function_calling": True,
                "json_output": True,
                "structured_output": False,
                "family": await _get_model_family(qwen_vl_least_model),
                "multiple_system_messages": True,
            },
        )
        print(f"âœ… åƒé—®è§†è§‰æ¨¡å‹å®¢æˆ·ç«¯å·²åˆ›å»º: {qwen_vl_least_model}")

    return _qwen_vl_least_client


async def default_model_client(settings: Optional[Settings] = None) -> OpenAIChatCompletionClient:
    """
    è·å–é»˜è®¤æ¨¡å‹å®¢æˆ·ç«¯ï¼Œç”¨äºé€šç”¨å¯¹è¯å’Œæ–‡æœ¬å¤„ç†

    å‚æ•°:
        settings: é…ç½®å®ä¾‹ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨å…¨å±€é…ç½®

    è¿”å›:
        OpenAIChatCompletionClient å®ä¾‹
    """
    global _default_model_client

    if _default_model_client is None:
        if settings is None:
            from config import settings as global_settings
            settings = global_settings

        _default_model_client = OpenAIChatCompletionClient(
            model=settings.model_name,
            api_key=settings.api_key,
            base_url=settings.base_url,
            model_info={
                "vision": False,
                "function_calling": True,
                "json_output": True,
                "structured_output": False,
                "family": await _get_model_family(settings.model_name),
                "multiple_system_messages": True,
            },
        )
        print(f"âœ… é»˜è®¤æ¨¡å‹å®¢æˆ·ç«¯å·²åˆ›å»º: {settings.model_name}")

    return _default_model_client


def get_default_model_client(settings: Optional[Settings] = None) -> OpenAIChatCompletionClient:
    """
    åŒæ­¥è·å–é»˜è®¤æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆç”¨äºå…¼å®¹æ€§ï¼‰

    å‚æ•°:
        settings: é…ç½®å®ä¾‹ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨å…¨å±€é…ç½®

    è¿”å›:
        OpenAIChatCompletionClient å®ä¾‹
    """
    if settings is None:
        from config import settings as global_settings
        settings = global_settings

    return OpenAIChatCompletionClient(
        model=settings.model_name,
        api_key=settings.api_key,
        base_url=settings.base_url,
        model_info={
            "vision": False,
            "function_calling": True,
            "json_output": True,
            "structured_output": False,
            "family": "deepseek",  # ç®€åŒ–å¤„ç†
            "multiple_system_messages": True,
        },
    )


async def _get_model_family(model_name: Optional[str]) -> str:
    """
    æ ¹æ®æ¨¡å‹åç§°æ¨æ–­æ¨¡å‹å®¶æ—

    å‚æ•°:
        model_name: æ¨¡å‹åç§°ï¼Œå¯ä»¥ä¸º None

    è¿”å›:
        æ¨¡å‹å®¶æ—åç§°
    """
    if model_name is None:
        return "unknown"

    model_name_lower = model_name.lower()

    if "deepseek" in model_name_lower:
        return "deepseek"
    elif "gpt" in model_name_lower or "openai" in model_name_lower:
        return "openai"
    elif "claude" in model_name_lower:
        return "anthropic"
    elif "gemini" in model_name_lower:
        return "google"
    elif "qwen" in model_name_lower:
        return "qwen"
    elif "doubao" in model_name_lower or "ui-tars" in model_name_lower:
        return "doubao"
    else:
        return "unknown"


async def reset_model_clients() -> None:
    """
    é‡ç½®æ‰€æœ‰æ¨¡å‹å®¢æˆ·ç«¯ç¼“å­˜
    ç”¨äºé…ç½®æ›´æ–°åé‡æ–°åˆå§‹åŒ–å®¢æˆ·ç«¯
    """
    global _uitars_model_client, _qwen_vl_least_client, _default_model_client, _deepseek_model_client

    _uitars_model_client = None
    _qwen_vl_least_client = None
    _default_model_client = None
    _deepseek_model_client = None

    print("ğŸ”„ æ‰€æœ‰æ¨¡å‹å®¢æˆ·ç«¯ç¼“å­˜å·²é‡ç½®")

