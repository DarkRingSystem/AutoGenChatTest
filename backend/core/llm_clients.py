"""
LLM æ¨¡å‹å®¢æˆ·ç«¯ç®¡ç†æ¨¡å—
æä¾›å„ç§ LLM æ¨¡å‹å®¢æˆ·ç«¯çš„åˆ›å»ºå’Œç®¡ç†åŠŸèƒ½
æ”¯æŒ UI è‡ªåŠ¨åŒ–ã€å›¾åƒåˆ†æç­‰å¤šç§åœºæ™¯
"""
from typing import Optional
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_core.models import ModelInfo
from config import Settings

# å…¨å±€æ¨¡å‹å®¢æˆ·ç«¯ç¼“å­˜
_uitars_model_client: Optional[OpenAIChatCompletionClient] = None
_vision_model_client: Optional[OpenAIChatCompletionClient] = None
_default_model_client: Optional[OpenAIChatCompletionClient] = None


def get_uitars_model_client(settings: Optional[Settings] = None) -> OpenAIChatCompletionClient:
    """
    è·å– UI-TARS æ¨¡å‹å®¢æˆ·ç«¯ï¼Œç”¨äº UI è‡ªåŠ¨åŒ–å’Œå›¾åƒåˆ†æ

    å‚æ•°:
        settings: é…ç½®å®ä¾‹ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨å…¨å±€é…ç½®

    è¿”å›:
        OpenAIChatCompletionClient å®ä¾‹
    """
    global _uitars_model_client

    if _uitars_model_client is None:
        if settings is None:
            from config import settings as global_settings
            settings = global_settings

        # ä»é…ç½®ä¸­è·å– UI-TARS æ¨¡å‹ä¿¡æ¯
        uitars_model = getattr(settings, 'uitars_model', 'gpt-4o')
        uitars_api_key = getattr(settings, 'uitars_api_key', settings.api_key)
        uitars_base_url = getattr(settings, 'uitars_base_url', settings.base_url)

        # è°ƒè¯•ä¿¡æ¯
        print(f"\nğŸ” UI-TARS æ¨¡å‹é…ç½®:")
        print(f"   æ¨¡å‹: {uitars_model}")
        print(f"   API Key: {uitars_api_key[:20]}...{uitars_api_key[-10:] if uitars_api_key and len(uitars_api_key) > 30 else uitars_api_key}")
        print(f"   Base URL: {uitars_base_url}")

        _uitars_model_client = OpenAIChatCompletionClient(
            model=uitars_model,
            api_key=uitars_api_key,
            base_url=uitars_base_url,
            model_info={
                "vision": True,
                "function_calling": True,
                "json_output": True,
                "structured_output": True,
                "family": "unknown",
                "multiple_system_messages": True,
            },
        )
        print(f"âœ… UI-TARS æ¨¡å‹å®¢æˆ·ç«¯å·²åˆ›å»ºæˆåŠŸ")

    return _uitars_model_client


def get_vision_model_client(settings: Optional[Settings] = None) -> OpenAIChatCompletionClient:
    """
    è·å–è§†è§‰æ¨¡å‹å®¢æˆ·ç«¯ï¼Œç”¨äºå›¾åƒç†è§£å’Œåˆ†æ

    å‚æ•°:
        settings: é…ç½®å®ä¾‹ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨å…¨å±€é…ç½®

    è¿”å›:
        OpenAIChatCompletionClient å®ä¾‹
    """
    global _vision_model_client

    if _vision_model_client is None:
        if settings is None:
            from config import settings as global_settings
            settings = global_settings

        # ä»é…ç½®ä¸­è·å–è§†è§‰æ¨¡å‹ä¿¡æ¯
        vision_model = getattr(settings, 'vision_model', settings.model_name)
        vision_api_key = getattr(settings, 'vision_api_key', settings.api_key)
        vision_base_url = getattr(settings, 'vision_base_url', settings.base_url)

        _vision_model_client = OpenAIChatCompletionClient(
            model=vision_model,
            api_key=vision_api_key,
            base_url=vision_base_url,
            model_info={
                "vision": True,
                "function_calling": True,
                "json_output": True,
                "structured_output": False,
                "family": _get_model_family(vision_model),
                "multiple_system_messages": True,
            },
        )
        print(f"âœ… è§†è§‰æ¨¡å‹å®¢æˆ·ç«¯å·²åˆ›å»º: {vision_model}")

    return _vision_model_client


def get_default_model_client(settings: Optional[Settings] = None) -> OpenAIChatCompletionClient:
    """
    è·å–é»˜è®¤æ¨¡å‹å®¢æˆ·ç«¯ï¼Œç”¨äºé€šç”¨å¯¹è¯å’Œæ–‡æœ¬å¤„ç†

    å‚æ•°:
        settings: é…ç½®å®ä¾‹ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨å…¨å±€é…ç½®

    è¿”å›:
        OpenAIChatCompletionClient å®ä¾‹
    """
    global _default_model_client

    if _default_model_client is None:
        if settings is None:
            from config import settings as global_settings
            settings = global_settings

        _default_model_client = OpenAIChatCompletionClient(
            model=settings.model_name,
            api_key=settings.api_key,
            base_url=settings.base_url,
            model_info={
                "vision": False,
                "function_calling": True,
                "json_output": True,
                "structured_output": False,
                "family": _get_model_family(settings.model_name),
                "multiple_system_messages": True,
            },
        )
        print(f"âœ… é»˜è®¤æ¨¡å‹å®¢æˆ·ç«¯å·²åˆ›å»º: {settings.model_name}")

    return _default_model_client


def _get_model_family(model_name: Optional[str]) -> str:
    """
    æ ¹æ®æ¨¡å‹åç§°æ¨æ–­æ¨¡å‹å®¶æ—

    å‚æ•°:
        model_name: æ¨¡å‹åç§°ï¼Œå¯ä»¥ä¸º None

    è¿”å›:
        æ¨¡å‹å®¶æ—åç§°
    """
    if model_name is None:
        return "unknown"

    model_name_lower = model_name.lower()

    if "deepseek" in model_name_lower:
        return "deepseek"
    elif "gpt" in model_name_lower or "openai" in model_name_lower:
        return "openai"
    elif "claude" in model_name_lower:
        return "anthropic"
    elif "gemini" in model_name_lower:
        return "google"
    elif "qwen" in model_name_lower:
        return "qwen"
    elif "doubao" in model_name_lower or "ui-tars" in model_name_lower:
        return "doubao"
    else:
        return "unknown"


def reset_model_clients() -> None:
    """
    é‡ç½®æ‰€æœ‰æ¨¡å‹å®¢æˆ·ç«¯ç¼“å­˜
    ç”¨äºé…ç½®æ›´æ–°åé‡æ–°åˆå§‹åŒ–å®¢æˆ·ç«¯
    """
    global _uitars_model_client, _vision_model_client, _default_model_client

    _uitars_model_client = None
    _vision_model_client = None
    _default_model_client = None

    print("ğŸ”„ æ‰€æœ‰æ¨¡å‹å®¢æˆ·ç«¯ç¼“å­˜å·²é‡ç½®")

