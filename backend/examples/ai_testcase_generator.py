"""
AIæµ‹è¯•ç”¨ä¾‹ç”ŸæˆAPI
ç”¨äºå¯åŠ¨æ™ºèƒ½ä½“å·¥ä½œæµå¹¶æµå¼è¿”å›ç»“æœ
"""
import uuid
import asyncio
import logging
from datetime import datetime
from typing import Dict, Any, Optional, AsyncGenerator
from fastapi import APIRouter, HTTPException, Request
from fastapi.responses import StreamingResponse
from pydantic import BaseModel

from app.core.orchestrator_service import TestCaseOrchestrator
from app.models.test_case import ImageAnalysisRequest, TestCaseGenerationRequest

# æ·»åŠ utilsè·¯å¾„åˆ°sys.path
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
from utils.sse_stream_service import SSEStreamService

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/ai-testcase-generator", tags=["AIæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ"])

# å…¨å±€ä¼šè¯å­˜å‚¨
active_sessions: Dict[str, Dict[str, Any]] = {}
orchestrators: Dict[str, TestCaseOrchestrator] = {}

class GenerationStartRequest(BaseModel):
    """å¼€å§‹ç”Ÿæˆè¯·æ±‚"""
    session_id: Optional[str] = None
    file_path: Optional[str] = None
    file_name: Optional[str] = None
    description: Optional[str] = None
    agent_type: str = "image_analysis"

class SessionResponse(BaseModel):
    """ä¼šè¯å“åº”"""
    session_id: str
    status: str
    message: str

@router.post("/session/create", response_model=SessionResponse)
async def create_session():
    """åˆ›å»ºæ–°çš„ç”Ÿæˆä¼šè¯"""
    try:
        session_id = str(uuid.uuid4())

        # åˆå§‹åŒ–ä¼šè¯æ•°æ®
        active_sessions[session_id] = {
            "session_id": session_id,
            "status": "created",
            "created_at": datetime.now(),
            "messages": [],
            "orchestrator": None
        }

        logger.info(f"åˆ›å»ºæ–°ä¼šè¯: {session_id}")

        return SessionResponse(
            session_id=session_id,
            status="created",
            message="ä¼šè¯åˆ›å»ºæˆåŠŸ"
        )

    except Exception as e:
        logger.error(f"åˆ›å»ºä¼šè¯å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºä¼šè¯å¤±è´¥: {str(e)}")

@router.post("/session/{session_id}/start")
async def start_generation(
    session_id: str,
    request: GenerationStartRequest
):
    """å¼€å§‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹"""
    try:
        if session_id not in active_sessions:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        session = active_sessions[session_id]
        session["status"] = "starting"

        # ä¿å­˜è¯·æ±‚ä¿¡æ¯åˆ°ä¼šè¯ä¸­
        if request.file_name:
            # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            file_path = request.file_path or f"backend/uploads/ai_files/{request.file_name}"

            # æ„å»ºç»å¯¹è·¯å¾„è¿›è¡ŒéªŒè¯
            if not os.path.isabs(file_path):
                current_dir = os.path.dirname(__file__)  # backend/app/api
                backend_dir = os.path.dirname(os.path.dirname(current_dir))  # backend
                project_root = os.path.dirname(backend_dir)  # é¡¹ç›®æ ¹ç›®å½•
                abs_file_path = os.path.join(project_root, file_path)
            else:
                abs_file_path = file_path

            if not os.path.exists(abs_file_path):
                logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {abs_file_path}")
                raise HTTPException(status_code=400, detail=f"æ–‡ä»¶ä¸å­˜åœ¨: {request.file_name}")

            session["file_name"] = request.file_name
            session["file_path"] = file_path
            logger.info(f"ä¼šè¯ {session_id} ä¿å­˜æ–‡ä»¶ä¿¡æ¯: {request.file_name} -> {abs_file_path}")

        if request.description:
            session["description"] = request.description

        # åˆ›å»ºç¼–æ’å™¨
        orchestrator = TestCaseOrchestrator(session_id=session_id)
        orchestrators[session_id] = orchestrator
        session["orchestrator"] = orchestrator

        # æ ¹æ®æ™ºèƒ½ä½“ç±»å‹å¯åŠ¨ä¸åŒçš„å·¥ä½œæµ
        if request.agent_type == "image_analysis" and (request.file_path or request.file_name):
            # æ„å»ºæ–‡ä»¶è·¯å¾„
            file_path = request.file_path or f"backend/uploads/ai_files/{request.file_name}"

            # å¯åŠ¨å›¾ç‰‡åˆ†æå·¥ä½œæµ
            analysis_request = ImageAnalysisRequest(
                session_id=session_id,
                image_name=request.file_name or "uploaded_image",
                image_path=file_path,
                image_description=request.description,
                analysis_target="UIæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ"
            )

            # å¼‚æ­¥å¯åŠ¨å·¥ä½œæµ
            task = asyncio.create_task(orchestrator.analyze_image(analysis_request))

            # æ·»åŠ å¼‚å¸¸å¤„ç†å›è°ƒ
            def handle_task_exception(task):
                if task.exception():
                    logger.error(f"å›¾ç‰‡åˆ†æä»»åŠ¡å¼‚å¸¸: {task.exception()}")
                    session["status"] = "error"

            task.add_done_callback(handle_task_exception)

        else:
            # å¯åŠ¨æ–‡æœ¬ç”Ÿæˆå·¥ä½œæµ
            generation_request = TestCaseGenerationRequest(
                source_type="text",
                source_data={"description": request.description or ""},
                test_cases=[],
                generation_config={"auto_save": True}
            )

            # å¼‚æ­¥å¯åŠ¨å·¥ä½œæµ
            asyncio.create_task(orchestrator.generate_test_cases(generation_request))

        session["status"] = "running"

        return SessionResponse(
            session_id=session_id,
            status="running",
            message="æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå·²å¯åŠ¨"
        )

    except Exception as e:
        logger.error(f"å¯åŠ¨ç”Ÿæˆå¤±è´¥: {str(e)}")
        if session_id in active_sessions:
            active_sessions[session_id]["status"] = "error"
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨ç”Ÿæˆå¤±è´¥: {str(e)}")

@router.get("/session/{session_id}/stream")
async def stream_generation_progress(session_id: str, request: Request):
    """æµå¼è·å–ç”Ÿæˆè¿›åº¦"""
    try:
        if session_id not in active_sessions:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        async def generate_stream():
            """ç”ŸæˆSSEæµ"""
            try:
                session = active_sessions[session_id]
                orchestrator = orchestrators.get(session_id)

                if not orchestrator:
                    yield f"data: {{'type': 'error', 'content': 'ç¼–æ’å™¨æœªæ‰¾åˆ°'}}\n\n"
                    return

                # å‘é€å¼€å§‹æ¶ˆæ¯
                yield f"data: {{'type': 'status', 'content': 'ğŸš€ å¼€å§‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...'}}\n\n"

                # ç›‘å¬ç¼–æ’å™¨çš„æ¶ˆæ¯
                message_count = 0
                max_messages = 100000000000  # é˜²æ­¢æ— é™å¾ªç¯
                timeout_count = 0
                max_timeout = 600000  # 10åˆ†é’Ÿè¶…æ—¶ (6000 * 0.1s)

                logger.info(f"å¼€å§‹ç›‘å¬æ¶ˆæ¯: {session_id}")

                while message_count < max_messages and timeout_count < max_timeout:
                    if await request.is_disconnected():
                        logger.info(f"å®¢æˆ·ç«¯æ–­å¼€è¿æ¥: {session_id}")
                        break

                    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ¶ˆæ¯
                    if orchestrator.response_collector:
                        messages = await orchestrator.response_collector.get_messages()
                        if messages:
                            logger.info(f"æ”¶åˆ° {len(messages)} æ¡æ–°æ¶ˆæ¯")
                            for message in messages:
                                yield f"data: {message}\n\n"
                                message_count += 1

                                # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥ä½œæµå®Œæˆæ¶ˆæ¯
                                if isinstance(message, dict) and message.get("content") == "WORKFLOW_COMPLETED":
                                    logger.info(f"å·¥ä½œæµå®Œæˆ: {session_id}")
                                    session["status"] = "completed"
                                elif isinstance(message, dict) and message.get("content") == "WORKFLOW_ERROR":
                                    logger.info(f"å·¥ä½œæµé”™è¯¯: {session_id}")
                                    session["status"] = "error"

                            timeout_count = 0  # é‡ç½®è¶…æ—¶è®¡æ•°
                        else:
                            timeout_count += 1
                    else:
                        timeout_count += 1

                    # æ£€æŸ¥ä¼šè¯çŠ¶æ€
                    if session.get("status") == "completed":
                        logger.info(f"ä¼šè¯å®Œæˆ: {session_id}")
                        yield f"data: {{'type': 'done', 'content': 'âœ… æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆ'}}\n\n"
                        break
                    elif session.get("status") == "error":
                        logger.info(f"ä¼šè¯é”™è¯¯: {session_id}")
                        yield f"data: {{'type': 'error', 'content': 'âŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯'}}\n\n"
                        break

                    # çŸ­æš‚ç­‰å¾…
                    await asyncio.sleep(0.1)

                # è¶…æ—¶å¤„ç†
                if timeout_count >= max_timeout:
                    logger.warning(f"ä¼šè¯è¶…æ—¶: {session_id}")
                    yield f"data: {{'type': 'timeout', 'content': 'â° å¤„ç†è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•'}}\n\n"

                # å‘é€ç»“æŸæ¶ˆæ¯
                yield f"data: {{'type': 'end', 'content': 'Stream ended'}}\n\n"

            except Exception as e:
                logger.error(f"æµå¼ä¼ è¾“é”™è¯¯: {str(e)}")
                yield f"data: {{'type': 'error', 'content': 'æµå¼ä¼ è¾“é”™è¯¯: {str(e)}'}}\n\n"

        return StreamingResponse(
            generate_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "*",
            }
        )

    except Exception as e:
        logger.error(f"åˆ›å»ºæµå¼å“åº”å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºæµå¼å“åº”å¤±è´¥: {str(e)}")

@router.get("/session/{session_id}/status")
async def get_session_status(session_id: str):
    """è·å–ä¼šè¯çŠ¶æ€"""
    try:
        if session_id not in active_sessions:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        session = active_sessions[session_id]

        return {
            "session_id": session_id,
            "status": session.get("status", "unknown"),
            "created_at": session.get("created_at"),
            "message_count": len(session.get("messages", []))
        }

    except Exception as e:
        logger.error(f"è·å–ä¼šè¯çŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ä¼šè¯çŠ¶æ€å¤±è´¥: {str(e)}")

@router.delete("/session/{session_id}")
async def delete_session(session_id: str):
    """åˆ é™¤ä¼šè¯"""
    try:
        if session_id in active_sessions:
            del active_sessions[session_id]

        if session_id in orchestrators:
            # æ¸…ç†ç¼–æ’å™¨èµ„æº
            orchestrator = orchestrators[session_id]
            if hasattr(orchestrator, 'cleanup'):
                await orchestrator.cleanup()
            del orchestrators[session_id]

        return SessionResponse(
            session_id=session_id,
            status="deleted",
            message="ä¼šè¯å·²åˆ é™¤"
        )

    except Exception as e:
        logger.error(f"åˆ é™¤ä¼šè¯å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤ä¼šè¯å¤±è´¥: {str(e)}")


@router.get("/session/{session_id}/stream-direct", response_class=StreamingResponse)
async def stream_generation_direct(session_id: str, request: Request):
    """ç›´æ¥æµå¼ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼ˆæ–°çš„æµå¼å®ç°ï¼‰"""
    try:
        if session_id not in active_sessions:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        session = active_sessions[session_id]

        async def generate_direct_stream():
            """ä»ResponseCollectorè¯»å–Agentçš„æµå¼è¾“å‡ºï¼ˆä»…region: agentçš„æ¶ˆæ¯ï¼‰"""
            import json
            try:
                # è·å–ç¼–æ’å™¨
                orchestrator = orchestrators.get(session_id)
                if not orchestrator:
                    yield "data: {\"type\": \"error\", \"content\": \"ç¼–æ’å™¨æœªæ‰¾åˆ°\"}\n\n"
                    return

                # è·å–ResponseCollector
                response_collector = orchestrator.response_collector
                if not response_collector:
                    yield "data: {\"type\": \"error\", \"content\": \"ResponseCollectoræœªæ‰¾åˆ°\"}\n\n"
                    return

                # å‘é€å¼€å§‹æ¶ˆæ¯
                yield "data: {\"type\": \"agent_start\", \"agent_name\": \"ç³»ç»Ÿ\"}\n\n"

                # æŒç»­è¯»å–ResponseCollectorä¸­çš„æ¶ˆæ¯ï¼Œåªè½¬å‘regionä¸º"agent"çš„æ¶ˆæ¯
                timeout_count = 0
                max_timeout = 60  # æœ€å¤§ç­‰å¾…60ç§’

                while timeout_count < max_timeout:
                    try:
                        # ç­‰å¾…æ¶ˆæ¯ï¼Œè¶…æ—¶æ—¶é—´ä¸º1ç§’
                        message = await asyncio.wait_for(
                            response_collector.message_queue.get(),
                            timeout=1.0
                        )

                        # åªè½¬å‘regionä¸º"agent"çš„æ¶ˆæ¯åˆ°AIå¯¹è¯åŒºåŸŸ
                        if message.region == "agent":
                            message_data = {
                                "type": message.type,
                                "content": message.content,
                                "agent_name": message.agent_name,
                                "region": "agent"
                            }
                            yield f"data: {json.dumps(message_data)}\n\n"

                        # å¦‚æœæ”¶åˆ°å®Œæˆæ¶ˆæ¯ï¼Œç»“æŸæµå¼è¾“å‡º
                        if message.type == "complete" or message.content == "âœ… æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆ":
                            break

                        timeout_count = 0  # é‡ç½®è¶…æ—¶è®¡æ•°

                    except asyncio.TimeoutError:
                        timeout_count += 1
                        # å‘é€å¿ƒè·³æ¶ˆæ¯ï¼Œé¿å…å‰ç«¯è¶…æ—¶
                        if timeout_count % 10 == 0:  # æ¯10ç§’å‘é€ä¸€æ¬¡å¿ƒè·³
                            yield "data: {\"type\": \"heartbeat\", \"content\": \"ç­‰å¾…Agentå“åº”ä¸­...\", \"region\": \"agent\"}\n\n"
                        continue

                # å‘é€å®Œæˆæ¶ˆæ¯
                yield "data: {\"type\": \"agent_done\", \"agent_name\": \"ç³»ç»Ÿ\"}\n\n"

                # æ›´æ–°ä¼šè¯çŠ¶æ€
                session["status"] = "completed"

            except Exception as e:
                logger.error(f"ç›´æ¥æµå¼ç”Ÿæˆå¤±è´¥: {str(e)}")
                yield f"data: {{\"type\": \"error\", \"content\": \"ç”Ÿæˆå¤±è´¥: {str(e)}\"}}\n\n"
                session["status"] = "error"

        return StreamingResponse(
            generate_direct_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "*",
            }
        )

    except Exception as e:
        logger.error(f"ç›´æ¥æµå¼ä¼ è¾“å¤±è´¥: {str(e)}")
        import traceback
        logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")

        error_message = str(e)

        async def error_stream():
            yield f"data: {{\"type\": \"error\", \"content\": \"ä¼ è¾“å¤±è´¥: {error_message}\"}}\n\n"

        return StreamingResponse(
            error_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "*",
            }
        )


async def stream_image_analysis(request: ImageAnalysisRequest) -> AsyncGenerator[str, None]:
    """æµå¼å›¾ç‰‡åˆ†æ - çœŸå®æ¨¡å‹è°ƒç”¨"""
    try:
        from autogen_agentchat.messages import MultiModalMessage
        from autogen_core import Image
        from app.core.llms import _get_uitars_model_client
        import json
        import os

        # å‘é€æ™ºèƒ½ä½“å¼€å§‹æ¶ˆæ¯
        yield "data: {\"type\": \"agent_start\", \"agent_name\": \"UIç•Œé¢åˆ†ææ™ºèƒ½ä½“\"}\n\n"

        # ä½¿ç”¨llms.pyä¸­çš„UI-TARSæ¨¡å‹å®¢æˆ·ç«¯
        model_client = _get_uitars_model_client()

        # åŠ è½½å›¾ç‰‡ - ç¡®ä¿è·¯å¾„æ­£ç¡®
        image_path = request.image_path
        if not os.path.isabs(image_path):
            # ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦ä»é¡¹ç›®æ ¹ç›®å½•å¼€å§‹
            # å½“å‰æ–‡ä»¶åœ¨ backend/app/api/ï¼Œéœ€è¦å›åˆ°é¡¹ç›®æ ¹ç›®å½•
            current_dir = os.path.dirname(__file__)  # backend/app/api
            backend_dir = os.path.dirname(os.path.dirname(current_dir))  # backend
            project_root = os.path.dirname(backend_dir)  # é¡¹ç›®æ ¹ç›®å½•
            image_path = os.path.join(project_root, image_path)

        logger.info(f"å°è¯•åŠ è½½å›¾ç‰‡: {image_path}")
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")

        image = Image.from_file(image_path)

        # æ„å»ºåˆ†ææç¤ºè¯
        prompt = f"""
è¯·åˆ†æè¿™å¼ UIç•Œé¢æˆªå›¾ï¼Œè¯†åˆ«ä»¥ä¸‹å†…å®¹ï¼š
1. ç•Œé¢ç±»å‹ï¼ˆç™»å½•é¡µé¢ã€ä¸»é¡µã€è¡¨å•é¡µé¢ç­‰ï¼‰
2. ä¸»è¦UIå…ƒç´ ï¼ˆæŒ‰é’®ã€è¾“å…¥æ¡†ã€é“¾æ¥ã€å›¾ç‰‡ç­‰ï¼‰
3. ç•Œé¢å¸ƒå±€ç»“æ„
4. å¯èƒ½çš„äº¤äº’åŠŸèƒ½
5. éœ€è¦æµ‹è¯•çš„å…³é”®åŠŸèƒ½ç‚¹

å›¾ç‰‡åç§°: {request.image_name}
åˆ†æç›®æ ‡: {request.analysis_target or 'å…¨é¢åˆ†æUIç•Œé¢'}

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚
"""

        # åˆ›å»ºå¤šæ¨¡æ€æ¶ˆæ¯
        multi_modal_message = MultiModalMessage(
            content=[prompt, image],
            source="user"
        )

        # è½¬æ¢ä¸ºæ¨¡å‹æ¶ˆæ¯
        user_message = multi_modal_message.to_model_message()

        # çœŸå®æµå¼è°ƒç”¨æ¨¡å‹
        analysis_text = ""

        # ä½¿ç”¨çœŸå®çš„UI-TARSæ¨¡å‹APIè°ƒç”¨
        try:
            async for chunk in model_client.create_stream([user_message]):
                if hasattr(chunk, 'content') and chunk.content:
                    analysis_text += chunk.content
                    # å‘é€æµå¼å†…å®¹åˆ°AIå¯¹è¯åŒºåŸŸ
                    yield f"data: {{\"type\": \"chunk\", \"content\": {json.dumps(chunk.content)}, \"agent_name\": \"UIç•Œé¢åˆ†ææ™ºèƒ½ä½“\", \"region\": \"agent\"}}\n\n"
        except Exception as e:
            logger.error(f"UI-TARSæ¨¡å‹è°ƒç”¨å¤±è´¥: {str(e)}")
            # å¦‚æœæ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºé™çº§æ–¹æ¡ˆ
            logger.warning("æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºé™çº§æ–¹æ¡ˆ")
            mock_chunks = [
                "æˆ‘æ­£åœ¨åˆ†æè¿™å¼ UIç•Œé¢æˆªå›¾...\n\n",
                "è¿™æ˜¯ä¸€ä¸ªç™»å½•é¡µé¢ï¼ŒåŒ…å«ä»¥ä¸‹ä¸»è¦å…ƒç´ ï¼š\n",
                "1. æ‰‹æœºå·è¾“å…¥æ¡†\n",
                "2. éªŒè¯ç è¾“å…¥æ¡†\n",
                "3. å¯†ç è¾“å…¥æ¡†\n",
                "4. ç™»å½•æŒ‰é’®\n",
                "5. åˆ‡æ¢ç™»å½•æ–¹å¼çš„é€‰é¡¹\n\n",
                "ç•Œé¢å¸ƒå±€é‡‡ç”¨å‚ç›´æ’åˆ—ï¼Œç¬¦åˆç§»åŠ¨ç«¯è®¾è®¡è§„èŒƒã€‚\n",
                "éœ€è¦é‡ç‚¹æµ‹è¯•æ‰‹æœºå·éªŒè¯ç ç™»å½•å’Œå¯†ç ç™»å½•åŠŸèƒ½çš„åˆ‡æ¢ã€‚"
            ]

            for chunk_content in mock_chunks:
                analysis_text += chunk_content
                yield f"data: {{\"type\": \"chunk\", \"content\": {json.dumps(chunk_content)}, \"agent_name\": \"UIç•Œé¢åˆ†ææ™ºèƒ½ä½“\", \"region\": \"agent\"}}\n\n"
                await asyncio.sleep(0.5)

        # å‘é€æ™ºèƒ½ä½“å®Œæˆæ¶ˆæ¯
        yield "data: {\"type\": \"agent_done\", \"agent_name\": \"UIç•Œé¢åˆ†ææ™ºèƒ½ä½“\"}\n\n"

        # è§£æåˆ†æç»“æœ
        try:
            analysis_result = json.loads(analysis_text)
        except json.JSONDecodeError:
            analysis_result = {
                "interface_type": "UIç•Œé¢",
                "ui_elements": [],
                "layout": "æœªçŸ¥å¸ƒå±€",
                "key_functions": [],
                "test_points": [],
                "raw_analysis": analysis_text
            }

        # æ·»åŠ ç”¨æˆ·æè¿°
        if request.image_description:
            analysis_result["user_description"] = request.image_description

        # å‘é€åˆ†æå®Œæˆæ¶ˆæ¯
        yield f"data: {{\"type\": \"analysis_complete\", \"analysis_result\": {json.dumps(analysis_result)}}}\n\n"

    except Exception as e:
        logger.error(f"æµå¼å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}")
        yield f"data: {{\"type\": \"error\", \"content\": \"å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}\"}}\n\n"


async def stream_test_case_generation(request: TestCaseGenerationRequest) -> AsyncGenerator[str, None]:
    """æµå¼æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ - çœŸå®æ¨¡å‹è°ƒç”¨"""
    try:
        from app.core.llms import _deepseek_model_client
        import json
        import os

        # å‘é€æ™ºèƒ½ä½“å¼€å§‹æ¶ˆæ¯
        yield "data: {\"type\": \"agent_start\", \"agent_name\": \"æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“\"}\n\n"

        # ä½¿ç”¨llms.pyä¸­çš„DeepSeekæ¨¡å‹å®¢æˆ·ç«¯
        try:
            model_client = _deepseek_model_client()
        except Exception as e:
            logger.error(f"åˆ›å»ºDeepSeekæ¨¡å‹å®¢æˆ·ç«¯å¤±è´¥: {str(e)}")
            model_client = None

        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        analysis_result = request.source_data
        user_description = analysis_result.get("user_description", "")

        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„UIæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆä¸“å®¶ã€‚

åŸºäºä»¥ä¸‹UIç•Œé¢åˆ†æç»“æœï¼Œç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•ç”¨ä¾‹ï¼š

{json.dumps(analysis_result, ensure_ascii=False, indent=2)}

è¯·ç”Ÿæˆå…¨é¢çš„æµ‹è¯•ç”¨ä¾‹ï¼ŒåŒ…æ‹¬ï¼š
- åŠŸèƒ½æµ‹è¯•ç”¨ä¾‹
- ç•Œé¢æµ‹è¯•ç”¨ä¾‹
- å…¼å®¹æ€§æµ‹è¯•ç”¨ä¾‹ï¼ˆä¸åŒè®¾å¤‡ã€æµè§ˆå™¨ï¼‰

æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹åº”åŒ…å«ï¼š
- ç”¨ä¾‹æ ‡é¢˜
- æµ‹è¯•æ­¥éª¤
- é¢„æœŸç»“æœ
- å‰ç½®æ¡ä»¶
- æµ‹è¯•æ•°æ®

è¯·ä»¥JSONæ ¼å¼è¿”å›æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨ã€‚
"""

        # å¦‚æœæœ‰ç”¨æˆ·æè¿°ï¼Œæ·»åŠ ç”¨æˆ·éœ€æ±‚
        if user_description.strip():
            system_prompt += f"""

ç”¨æˆ·éœ€æ±‚æè¿°ï¼š
{user_description}

è¯·ç‰¹åˆ«å…³æ³¨ç”¨æˆ·æè¿°çš„éœ€æ±‚ï¼Œç¡®ä¿ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹èƒ½å¤Ÿè¦†ç›–ç”¨æˆ·å…³æ³¨çš„åŠŸèƒ½ç‚¹ã€‚"""

        # æ„å»ºæ¶ˆæ¯
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"ç”¨æˆ·éœ€æ±‚ï¼š{user_description}\n\nè¯·æ ¹æ®ä¸Šè¿°UIç•Œé¢åˆ†æç»“æœå’Œæˆ‘çš„éœ€æ±‚æè¿°ï¼Œç”Ÿæˆç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹ã€‚"}
        ]

        # çœŸå®æµå¼è°ƒç”¨æ¨¡å‹æˆ–ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        response_text = ""

        if model_client:
            # ä½¿ç”¨çœŸå®çš„æ¨¡å‹APIè°ƒç”¨
            try:
                async for chunk in model_client.create_stream(messages):
                    if hasattr(chunk, 'content') and chunk.content:
                        response_text += chunk.content
                        # å‘é€æµå¼å†…å®¹åˆ°AIå¯¹è¯åŒºåŸŸ
                        yield f"data: {{\"type\": \"chunk\", \"content\": {json.dumps(chunk.content)}, \"agent_name\": \"æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“\", \"region\": \"agent\"}}\n\n"
            except Exception as e:
                logger.error(f"æ¨¡å‹APIè°ƒç”¨å¤±è´¥: {str(e)}")
                error_msg = f"æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥: {str(e)}"
                yield f"data: {{\"type\": \"error\", \"content\": \"{error_msg}\"}}\n\n"
                return
        else:
            # å¦‚æœæ²¡æœ‰é…ç½®APIå¯†é’¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            logger.warning("æœªé…ç½®APIå¯†é’¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæµ‹è¯•ç”¨ä¾‹æ•°æ®")
            mock_test_chunks = [
                "æ­£åœ¨åŸºäºUIç•Œé¢åˆ†æç»“æœç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...\n\n",
                "## åŠŸèƒ½æµ‹è¯•ç”¨ä¾‹\n\n",
                "### æµ‹è¯•ç”¨ä¾‹1ï¼šæ‰‹æœºå·éªŒè¯ç ç™»å½•\n",
                "- å‰ç½®æ¡ä»¶ï¼šç”¨æˆ·å·²å®‰è£…åº”ç”¨\n",
                "- æµ‹è¯•æ­¥éª¤ï¼š\n",
                "  1. æ‰“å¼€ç™»å½•é¡µé¢\n",
                "  2. é€‰æ‹©æ‰‹æœºå·éªŒè¯ç ç™»å½•æ–¹å¼\n",
                "  3. è¾“å…¥æœ‰æ•ˆæ‰‹æœºå·\n",
                "  4. ç‚¹å‡»è·å–éªŒè¯ç \n",
                "  5. è¾“å…¥æ­£ç¡®éªŒè¯ç \n",
                "  6. ç‚¹å‡»ç™»å½•æŒ‰é’®\n",
                "- é¢„æœŸç»“æœï¼šæˆåŠŸç™»å½•åˆ°ä¸»é¡µ\n\n",
                "### æµ‹è¯•ç”¨ä¾‹2ï¼šå¯†ç ç™»å½•\n",
                "- å‰ç½®æ¡ä»¶ï¼šç”¨æˆ·å·²æ³¨å†Œè´¦å·\n",
                "- æµ‹è¯•æ­¥éª¤ï¼š\n",
                "  1. æ‰“å¼€ç™»å½•é¡µé¢\n",
                "  2. é€‰æ‹©å¯†ç ç™»å½•æ–¹å¼\n",
                "  3. è¾“å…¥ç”¨æˆ·åå’Œå¯†ç \n",
                "  4. ç‚¹å‡»ç™»å½•æŒ‰é’®\n",
                "- é¢„æœŸç»“æœï¼šæˆåŠŸç™»å½•åˆ°ä¸»é¡µ\n\n",
                "### æµ‹è¯•ç”¨ä¾‹3ï¼šç™»å½•æ–¹å¼åˆ‡æ¢\n",
                "- æµ‹è¯•æ­¥éª¤ï¼š\n",
                "  1. åœ¨éªŒè¯ç ç™»å½•é¡µé¢ç‚¹å‡»åˆ‡æ¢åˆ°å¯†ç ç™»å½•\n",
                "  2. åœ¨å¯†ç ç™»å½•é¡µé¢ç‚¹å‡»åˆ‡æ¢åˆ°éªŒè¯ç ç™»å½•\n",
                "- é¢„æœŸç»“æœï¼šç•Œé¢æ­£ç¡®åˆ‡æ¢ï¼Œè¾“å…¥æ¡†çŠ¶æ€æ­£ç¡®\n\n",
                "æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆï¼"
            ]

            for chunk_content in mock_test_chunks:
                response_text += chunk_content
                yield f"data: {{\"type\": \"chunk\", \"content\": {json.dumps(chunk_content)}, \"agent_name\": \"æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“\", \"region\": \"agent\"}}\n\n"
                await asyncio.sleep(0.3)

        # å‘é€æ™ºèƒ½ä½“å®Œæˆæ¶ˆæ¯
        yield "data: {\"type\": \"agent_done\", \"agent_name\": \"æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“\"}\n\n"

    except Exception as e:
        logger.error(f"æµå¼æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥: {str(e)}")
        yield f"data: {{\"type\": \"error\", \"content\": \"æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥: {str(e)}\"}}\n\n"